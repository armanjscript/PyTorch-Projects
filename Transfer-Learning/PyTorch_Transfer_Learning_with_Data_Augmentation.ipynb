{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xPcbjKYLNCA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys, os\n",
        "from datetime import datetime\n",
        "from glob import glob\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUWd3-PNTKoQ",
        "outputId": "e9061011-49e7-47a7-f884-44893ea51313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --passive-ftp --prefer-family=ipv4 --ftp-user FoodImage@grebvm2.epfl.ch \\\n",
        " --ftp-password Cahc1moo -nc ftp://tremplin.epfl.ch/Food-5k.zip"
      ],
      "metadata": {
        "id": "U8iwvLEQQSe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq -o Food-5k.zip"
      ],
      "metadata": {
        "id": "niw_zY4V4Qv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "VzNXMfAo4cCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv Food-5k/*"
      ],
      "metadata": {
        "id": "yhL9KBbi8M_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#look at an image\n",
        "plt.imshow(imageio.read('training/0_808.jpg'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uPdsT-ddR-Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Food image start with 1, non-food images start with 0\n",
        "plt.imshow(imageio.read('training/1_616.jpg'))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MR3bmgl0-Vi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "obXpNZ2N7M58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Make directories to store the data Keras-style\n",
        "!mkdir data/train\n",
        "!mkdir data/test\n",
        "!mkdir data/train/nonfood\n",
        "!mkdir data/train/food\n",
        "!mkdir data/test/nonfood\n",
        "!mkdir data/test/food"
      ],
      "metadata": {
        "id": "LAFmz-qzCgS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Move the images (food, nonfood) from training and validation to train and test\n",
        "!mv training/0*.jpg  data/train/nonfood\n",
        "!mv training/1*.jpg  data/train/food\n",
        "!mv validation/0*.jpg  data/test/nonfood\n",
        "!mv validation/1*.jpg  data/test/food"
      ],
      "metadata": {
        "id": "AhaJTaIt72OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(),\n",
        "    transforms.CenterCrop(size = 224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(size=256),\n",
        "    transforms.CenterCrop(size = 224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "pfowNOe4Om9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(\n",
        "    'data/train',\n",
        "    transform = train_transform\n",
        ")\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    'data/test',\n",
        "    transform = test_transform\n",
        ")"
      ],
      "metadata": {
        "id": "X-jbsiSNRDJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False\n",
        ")"
      ],
      "metadata": {
        "id": "fd_OphUjRior"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define model\n",
        "model = models.vgg16(pretrained=True)"
      ],
      "metadata": {
        "id": "eRqJ0pljSnL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Freeze VGG Weights\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "V3X9r6HcBVid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "vCCAD2hKe6yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We want to replace the classifier\n",
        "model.classifier"
      ],
      "metadata": {
        "id": "1PIUJRHfeisO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = model.classifier[0].in_features\n",
        "n_features"
      ],
      "metadata": {
        "id": "kEpvoR1u60fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.classifier = nn.Linear(n_features, 2)"
      ],
      "metadata": {
        "id": "kQ-a0CM97Rry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "hQESyNfxthrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "q58CNFtMt54a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "lKUelFPXZB20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to encapsualte the training loop\n",
        "def  batch_gd(model, criterion, optimizer, train_loader, test_loader, epochs):\n",
        "  train_losses = np.zeros(epochs)\n",
        "  test_losses = np.zeros(epochs)\n",
        "\n",
        "  for it in range(epochs):\n",
        "    t0 = datetime.now()\n",
        "    train_loss = []\n",
        "    for inputs, targets in train_loader:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      train_loss.append(loss.item())\n",
        "\n",
        "    train_loss = np.mean(train_loss)\n",
        "\n",
        "    test_loss = []\n",
        "    for inputs, targets in test_loader:\n",
        "      inputs, targets = inputs.to(device), targets.to(device)\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "      test_loss.append(loss.item())\n",
        "    test_loss = np.mean(test_loss)\n",
        "\n",
        "    #Save losses\n",
        "    train_losses[it] = train_loss\n",
        "    test_losses[it] = test_loss\n",
        "\n",
        "    dt = datetime.now() - t0\n",
        "    print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss: .4f}, \\\n",
        "    Test Loss: {test_loss: .4f}, Duration: {dt}')\n",
        "  return train_losses, test_losses"
      ],
      "metadata": {
        "id": "6PROSNTsZiPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, test_losses = batch_gd(model, criterion, optimizer, train_loader, test_loader, 5)"
      ],
      "metadata": {
        "id": "LMzVD7KtaynS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the train loss  and test loss per iteration\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xH19hnOXbXqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "for inputs, targets in train_loader:\n",
        "  inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "  outputs  = model(inputs)\n",
        "\n",
        "  _,predictions = torch.max(outputs, 1)\n",
        "\n",
        "  n_correct += (predictions == targets).sum().item()\n",
        "  n_total += targets.shape[0]\n",
        "\n",
        "train_acc = n_correct / n_total\n",
        "\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "for inputs, targets in test_loader:\n",
        "  inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "  outputs  = model(inputs)\n",
        "\n",
        "  predictions = torch.max(outputs, 1)\n",
        "\n",
        "  n_correct += (predictions == targets).sum().item()\n",
        "  n_total += targets.shape[0]\n",
        "\n",
        "test_acc = n_correct / n_total\n",
        "\n",
        "print(f'Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "id": "viNzW7fBbiL5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}